{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_muCgl5J4zFc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from operator import itemgetter\n",
        "import json \n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZSK1i1F_TUq"
      },
      "outputs": [],
      "source": [
        "!pip install pickle5\n",
        "import pickle5 as pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwCbKUdY_f5V"
      },
      "outputs": [],
      "source": [
        "with open('/content/sample_data/hr(tuples).pkl', \"rb\") as fh:\n",
        "  data = pickle.load(fh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRemVWjrO0Co"
      },
      "outputs": [],
      "source": [
        "def getter(x, hr = True):\n",
        "    if isinstance(x,tuple):\n",
        "        return itemgetter(0)(x) if hr else itemgetter(1)(x)\n",
        "    else:\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJyTDGeG_3pj"
      },
      "outputs": [],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKureeEx_9te"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU8YBNPuNgNT"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svmkOgwJC9x7"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFaesBf0F-PO"
      },
      "outputs": [],
      "source": [
        "data.Stage.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqvN-KAoHlyn"
      },
      "outputs": [],
      "source": [
        "data['Target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ze1vXEHI-k7"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change timesteps round it, not important\n",
        "time_stamps = list(data.columns[2:-13])\n",
        "time_stamps = [i[:i.find('.')+3] for i in time_stamps]\n",
        "dic_rename = dict(zip(data.columns[2:-13], time_stamps))\n",
        "data.rename(columns = dic_rename, inplace = True)\n",
        "data.columns"
      ],
      "metadata": {
        "id": "ELhdhW3BdykH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spilting dataset into stages with hr and ppi\n",
        "stage_dic_hr = {}\n",
        "stage_dic_ppi = {}\n",
        "for s in data.Stage.unique():\n",
        "  stage_dic_hr[s] = data[(data['Stage'] == s) & (data['Target'] != 'BASELINE')].applymap(lambda x:getter(x))\n",
        "\n",
        "stage_dic_hr['BASELINE_STIM'] = data[(data['Stage'] == 'STIMULUS') & (data['Target'] == 'BASELINE')].applymap(lambda x:getter(x))\n",
        "stage_dic_hr['BASELINE_QEST'] = data[(data['Stage'] == 'QUESTIONNAIRES') & (data['Target'] == 'BASELINE')].applymap(lambda x:getter(x))\n",
        "\n",
        "for s in data.Stage.unique():\n",
        "  stage_dic_ppi[s] = data[(data['Stage'] == s) & (data['Target'] != 'BASELINE')].applymap(lambda x:getter(x, False))\n",
        "\n",
        "stage_dic_ppi['BASELINE_STIM'] = data[(data['Stage'] == 'STIMULUS') & (data['Target'] == 'BASELINE')].applymap(lambda x:getter(x, False))\n",
        "stage_dic_ppi['BASELINE_QEST'] = data[(data['Stage'] == 'QUESTIONNAIRES') & (data['Target'] == 'BASELINE')].applymap(lambda x:getter(x, False))"
      ],
      "metadata": {
        "id": "Wvw_Sy32Ai0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[(data['Participant'] == 44) & (data['Target'] == 'ENTHUSIASM')].index"
      ],
      "metadata": {
        "id": "QadzoiYsTiaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(data = data.iloc[684, 2:-13].map(lambda x:getter(x)).values)"
      ],
      "metadata": {
        "id": "wNuJPiFeqzgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stages = ['WASHOUT', 'STIMULUS', 'QUESTIONNAIRES']\n",
        "emodf_hr = {}\n",
        "for s in stages:\n",
        "  for emo in list(stage_dic_hr[s].Target.unique()):\n",
        "      emodf_hr[emo+'_'+s] = stage_dic_hr[s][stage_dic_hr[s]['Target'] == emo]\n",
        "\n",
        "emodf_ppi = {}\n",
        "for s in stages:\n",
        "  for emo in list(stage_dic_ppi[s].Target.unique()):\n",
        "      emodf_ppi[emo+'_'+s] = stage_dic_ppi[s][stage_dic_ppi[s]['Target'] == emo]\n"
      ],
      "metadata": {
        "id": "Th2ZsJQuiLJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emo_lensignalhr = {}\n",
        "for emo in emodf_hr:\n",
        "  emo_lensignalhr[emo] = (6290 - emodf_hr[emo].iloc[:, 2:-13].T.isna().sum())\n",
        "\n",
        "emo_lensignalppi = {}\n",
        "for emo in emodf_ppi:\n",
        "  emo_lensignalppi[emo] = (6290 - emodf_ppi[emo].iloc[:, 2:-13].T.isna().sum())\n"
      ],
      "metadata": {
        "id": "qdED7GiLwS39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_map = {k: ind  for ind, k in enumerate(data['Target'].unique())}\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['Target'])"
      ],
      "metadata": {
        "id": "XnRm5Pf-aggN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_hr = data[data['Stage'] == 'STIMULUS'].applymap(lambda x:getter(x))\n",
        "dataset_hr = dataset_hr.iloc[:, 2:-12]\n",
        "\n",
        "dataset_ppi = data[data['Stage'] == 'STIMULUS'].applymap(lambda x:getter(x, False))\n",
        "dataset_ppi = dataset_ppi.iloc[:, 2:-12]"
      ],
      "metadata": {
        "id": "YbXTYsIP18LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(df, target_map):\n",
        "  df = df.copy()\n",
        "\n",
        "  df['Target'].replace(target_map, inplace = True)\n",
        "  y = df['Target'].copy()\n",
        "  X = df.drop('Target', axis = 1).copy()\n",
        "  \n",
        "  X_train,  X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 123, stratify=y)\n",
        "\n",
        "  return X_train,  X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "UDeZ4dkPPqzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,  X_test, y_train, y_test = split_dataset(dataset_hr, target_map)"
      ],
      "metadata": {
        "id": "PjLcmDM9VJib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "dh1ZgFLYgJkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "D_eysOtTAqgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "eCxRTKQ_VKyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape = X_train.shape[1])\n",
        "\n",
        "h1 = tf.keras.layers.Dense(128, activation = 'relu')(inputs)\n",
        "h2 = tf.keras.layers.Dense(128, activation = 'relu')(h1)\n",
        "h3 = tf.keras.layers.Dense(64, activation = 'relu')(h2)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(11, activation = 'softmax')(h3)\n",
        "\n",
        "model_simple_dnn = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "print(model_simple_dnn.summary())"
      ],
      "metadata": {
        "id": "0ZTK3u_p9ze5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_dnn.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "history = model_simple_dnn.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    validation_split = 0.2,\n",
        "    batch_size = 32,\n",
        "    epochs = 50, \n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor = 'val_loss',\n",
        "            patience = 5,\n",
        "            restore_best_weights = True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "tePU4GGuiM8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeldnn_acc = model_simple_dnn.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Test Accuracy : {round(modeldnn_acc, 3)*100} %\")"
      ],
      "metadata": {
        "id": "odUmTT6nlt6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape = X_train.shape[1])\n",
        "\n",
        "expand_dim = tf.expand_dims(inputs, axis = 2)\n",
        "gru = tf.keras.layers.GRU(265, return_sequences = True)(expand_dim)\n",
        "flatten = tf.keras.layers.Flatten()(gru)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(11, activation = 'softmax')(flatten)\n",
        "\n",
        "model_gru = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "print(model_gru.summary())"
      ],
      "metadata": {
        "id": "a_jjwlTFxBRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "history = model_gru.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    validation_split = 0.2,\n",
        "    batch_size = 32,\n",
        "    epochs = 50, \n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor = 'val_loss',\n",
        "            patience = 5,\n",
        "            restore_best_weights = True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "q4coVFGpzSjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelgru_acc = model_gru.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Test Accuracy : {round(modelgru_acc, 3)*100} %\")"
      ],
      "metadata": {
        "id": "SOXdBStbzo5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = tf.keras.Sequential()\n",
        "\n",
        "model_lstm.add(tf.keras.layers.LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1],1)))\n",
        "model_lstm.add(tf.keras.layers.Dropout(0.2))\n",
        "model_lstm.add(tf.keras.layers.LSTM(units=50,return_sequences=True))\n",
        "model_lstm.add(tf.keras.layers.Dropout(0.2))\n",
        "model_lstm.add(tf.keras.layers.LSTM(units=50,return_sequences=True))\n",
        "model_lstm.add(tf.keras.layers.Dropout(0.2))\n",
        "model_lstm.add(tf.keras.layers.LSTM(units=50))\n",
        "model_lstm.add(tf.keras.layers.Dropout(0.2))\n",
        "model_lstm.add(tf.keras.layers.Dense(units=11,activation='softmax'))   \n",
        "\n",
        "\n",
        "model_lstm.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
        "print(model_lstm.summary())"
      ],
      "metadata": {
        "id": "DGNQpa6BRonq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_lstm.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    validation_split = 0.2,\n",
        "    batch_size = 32,\n",
        "    epochs = 50, \n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor = 'val_loss',\n",
        "            patience = 5,\n",
        "            restore_best_weights = True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "gsIJABHkR1lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modellstm_acc = model_lstm.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Test Accuracy : {round(modellstm_acc, 3)*100} %\")"
      ],
      "metadata": {
        "id": "YkAiP5YE_30m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}